{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac891d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8ae938df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the supported device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "# convert a df to tensor to be used in pytorch\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "def split_df():\n",
    "    df_X = pd.read_csv(\"bitcoin_train.csv\",usecols=[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 27, 28, 29, 32, 33, 34])\n",
    "    df_y = pd.read_csv(\"bitcoin_train.csv\",usecols=[37])\n",
    "    X = df_to_tensor(df_X)\n",
    "    y = df_to_tensor(df_y)\n",
    "    return train_test_split(X, y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2d650c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_csv(\"bitcoin_train.csv\",usecols=[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 27, 28, 29, 32, 33, 34])\n",
    "df_y = pd.read_csv(\"bitcoin_train.csv\",usecols=[37])\n",
    "X = df_to_tensor(df_X)\n",
    "y = df_to_tensor(df_y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "75adc1e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: [38]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v1/hpfy1s7j1p14y62b8dycr0d00000gn/T/ipykernel_11651/3791120139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bitcoin_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bitcoin_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0my_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;31m# error: Cannot determine type of 'names'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 self._validate_usecols_names(\n\u001b[0m\u001b[1;32m    147\u001b[0m                     \u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_validate_usecols_names\u001b[0;34m(self, usecols, names)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    914\u001b[0m                 \u001b[0;34mf\"Usecols do not match columns, columns expected but not found: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0;34mf\"{missing}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: [38]"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"bitcoin_train.csv\",usecols=[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 27, 28, 29, 32, 33, 34])\n",
    "y = pd.read_csv(\"bitcoin_train.csv\",usecols=[38])\n",
    "\n",
    "def y_2d(x):\n",
    "    if x == 1.0:\n",
    "        return 0\n",
    "    return 1\n",
    "    \n",
    "#y['second_label'] = y.apply(lambda x: y_2d(x[0]), axis = 1)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27aee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight.data)\n",
    "        nn.init.normal_(m.bias.data)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        super(Net, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(sizes) - 1):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "            layers.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.model.apply(init_weights)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        #pred = self.softmax(self.model.forward(x)).argmax()\n",
    "        #if pred == 0:\n",
    "        #    return torch.Tensor([1])\n",
    "        #return torch.Tensor([0])\n",
    "        \n",
    "        \n",
    "\n",
    "    def train(self, X_train, y_train, X_valid=None, y_valid=None,\n",
    "          eta=0.25, num_epochs=10, isPrint=True):\n",
    "        \"\"\"\n",
    "        Train the network with SGD \n",
    "\n",
    "        :param X_train: matrix of training features \n",
    "        :param y_train: matrix of vector-encoded labels \n",
    "        \"\"\"\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(self.parameters(), lr=eta)\n",
    "        # initialize shuffled indices \n",
    "        shuffled_inds = list(range(X_train.shape[0]))\n",
    "        # loop over training epochs \n",
    "        for ep in range(1, num_epochs+1):\n",
    "\n",
    "            # shuffle indices \n",
    "            np.random.shuffle(shuffled_inds)\n",
    "\n",
    "            # loop over training examples \n",
    "            for ind in shuffled_inds:\n",
    "                optimizer.zero_grad()\n",
    "                output = self.forward(torch.from_numpy(X_train[ind]).float())\n",
    "                loss = criterion(output, torch.from_numpy(y_train[ind]).float())\n",
    "                loss.backward() \n",
    "                optimizer.step() \n",
    "\n",
    "            # print mean loss every 10 epochs if requested \n",
    "            if isPrint and (ep % 10) == 0:\n",
    "                print(\"epoch {:3d}/{:3d}: \".format(ep, num_epochs), end=\"\")\n",
    "                print(\"  train loss: {:8.3f}\".format(self.compute_loss(X_train, y_train)), end=\"\")\n",
    "                if X_valid is not None:\n",
    "                    print(\"  validation loss: {:8.3f}\".format(self.compute_loss(X_valid, y_valid)))\n",
    "                else:\n",
    "                    print(\"\")\n",
    "\n",
    "    def compute_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        compute average loss for given data set \n",
    "        \n",
    "        :param X: matrix of features \n",
    "        :param y: matrix of vector-encoded labels \n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "        if len(y.shape) == 1:\n",
    "            y = y[np.newaxis, :]\n",
    "        criterion = nn.MSELoss()\n",
    "        for x, t in zip(X, y):\n",
    "            output = self.forward(torch.from_numpy(x).float())\n",
    "            loss += criterion(output, torch.from_numpy(t).float()).item()\n",
    "        return loss / X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2622e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight.data)\n",
    "        nn.init.normal_(m.bias.data)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        super(Net, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(sizes) - 1):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "            layers.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.model.apply(init_weights)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        #pred = self.softmax(self.model.forward(x)).argmax()\n",
    "        #if pred == 0:\n",
    "        #    return torch.Tensor([1])\n",
    "        #return torch.Tensor([0])\n",
    "        \n",
    "        \n",
    "\n",
    "    def train(self, X_train, y_train, X_valid=None, y_valid=None,\n",
    "          eta=0.25, num_epochs=10, isPrint=True):\n",
    "        \"\"\"\n",
    "        Train the network with SGD \n",
    "\n",
    "        :param X_train: matrix of training features \n",
    "        :param y_train: matrix of vector-encoded labels \n",
    "        \"\"\"\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(self.parameters(), lr=eta)\n",
    "        # initialize shuffled indices \n",
    "        shuffled_inds = list(range(X_train.shape[0]))\n",
    "        # loop over training epochs \n",
    "        for ep in range(1, num_epochs+1):\n",
    "\n",
    "            # shuffle indices \n",
    "            np.random.shuffle(shuffled_inds)\n",
    "\n",
    "            # loop over training examples \n",
    "            for ind in shuffled_inds:\n",
    "                optimizer.zero_grad()\n",
    "                output = self.forward(X_train[ind])\n",
    "                loss = criterion(output,y_train[ind])\n",
    "                loss.backward() \n",
    "                optimizer.step() \n",
    "\n",
    "            # print mean loss every 10 epochs if requested \n",
    "            if isPrint and (ep % 10) == 0:\n",
    "                print(\"epoch {:3d}/{:3d}: \".format(ep, num_epochs), end=\"\")\n",
    "                print(\"  train loss: {:8.3f}\".format(self.compute_loss(X_train, y_train)), end=\"\")\n",
    "                if X_valid is not None:\n",
    "                    print(\"  validation loss: {:8.3f}\".format(self.compute_loss(X_valid, y_valid)))\n",
    "                else:\n",
    "                    print(\"\")\n",
    "\n",
    "    def compute_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        compute average loss for given data set \n",
    "        \n",
    "        :param X: matrix of features \n",
    "        :param y: matrix of vector-encoded labels \n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "        if len(y.shape) == 1:\n",
    "            y = y[np.newaxis, :]\n",
    "        criterion = nn.MSELoss()\n",
    "        for x, t in zip(X, y):\n",
    "            output = self.forward(x)\n",
    "            loss += criterion(output, t).item()\n",
    "        return loss / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "081ac836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net([X_train.shape[1], 10, 10, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5133a59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10/100:   train loss:    0.253  validation loss:    0.248\n",
      "epoch  20/100:   train loss:    0.252  validation loss:    0.255\n",
      "epoch  30/100:   train loss:    0.247  validation loss:    0.251\n",
      "epoch  40/100:   train loss:    0.249  validation loss:    0.253\n",
      "epoch  50/100:   train loss:    0.249  validation loss:    0.253\n",
      "epoch  60/100:   train loss:    0.245  validation loss:    0.247\n",
      "epoch  70/100:   train loss:    0.246  validation loss:    0.246\n",
      "epoch  80/100:   train loss:    0.249  validation loss:    0.248\n",
      "epoch  90/100:   train loss:    0.248  validation loss:    0.252\n",
      "epoch 100/100:   train loss:    0.245  validation loss:    0.248\n"
     ]
    }
   ],
   "source": [
    "model.train(X_train, y_train, X_valid, y_valid, eta=0.10, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a08aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pred = model.forward(torch.from_numpy(X_valid[13]).float())\n",
    "loss_1 = loss(torch.round(pred), torch.Tensor([1]))\n",
    "loss_1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e500206",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d755ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial, in_features):\n",
    "    '''\n",
    "    Define NN model\n",
    "    \n",
    "    Inputs:\n",
    "        trial: Optuna's Study object\n",
    "        in_features (int): number of features\n",
    "    '''\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    #layers.append(nn.LogSoftmax(dim=1))\n",
    "    layers.append(nn.Sigmoid())\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9a137a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_b():\n",
    "    '''\n",
    "    Define NN model\n",
    "    \n",
    "    Inputs:\n",
    "        trial: Optuna's Study object\n",
    "        in_features (int): number of features\n",
    "    '''\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = 1\n",
    "    layers = []\n",
    "    \n",
    "    in_features = X_valid.shape[0]\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        out_features = 8 #trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        #p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        #layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.Sigmoid())\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1bd42c10",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "define_model_b() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v1/hpfy1s7j1p14y62b8dycr0d00000gn/T/ipykernel_11651/1920844848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDEVICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: define_model_b() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "DEVICE = get_device()\n",
    "CLASSES = 2\n",
    "model = define_model_b(X_train.shape[1]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02aeacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial, NUM_FEATURES).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "\n",
    "        X_train, X_valid, y_train, y_valid = split_df()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = F.mse_loss(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        #with torch.no_grad():\n",
    "        #    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        #        \n",
    "        #        output = model(X_valid)\n",
    "        #        # Get the index of the max log-probability.\n",
    "        #        pred = output.argmax(dim=1, keepdim=True)\n",
    "        #        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        #accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        output = model(X_valid)\n",
    "        y_hat = output.detach().apply_(lambda x: round(x))\n",
    "        correct = y_hat.eq(y_valid).sum().item()\n",
    "        accuracy = correct / X_valid.shape[0]\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8be3f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2463, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "criterion(output, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb33a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = output.detach().apply_(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "001719b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5601703940362087"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.eq(y_train).sum().item() / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "93d646c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = get_device()\n",
    "CLASSES = 1\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 100\n",
    "NUM_FEATURES = X_valid.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d12ea850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-25 16:54:54,273]\u001b[0m A new study created in memory with name: no-name-89f1965b-e5b7-49f7-8536-4fe60374fc52\u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:55,380]\u001b[0m Trial 0 finished with value: 0.5782747603833865 and parameters: {'n_layers': 3, 'n_units_l0': 34, 'dropout_l0': 0.3768938809309429, 'n_units_l1': 20, 'dropout_l1': 0.41453735681957093, 'n_units_l2': 59, 'dropout_l2': 0.3778615869451023, 'optimizer': 'SGD', 'lr': 0.0009460704260547728}. Best is trial 0 with value: 0.5782747603833865.\u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:56,299]\u001b[0m Trial 1 finished with value: 0.48562300319488816 and parameters: {'n_layers': 1, 'n_units_l0': 65, 'dropout_l0': 0.3245672090851371, 'optimizer': 'SGD', 'lr': 1.1097815723469417e-05}. Best is trial 0 with value: 0.5782747603833865.\u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:57,242]\u001b[0m Trial 2 finished with value: 0.5718849840255591 and parameters: {'n_layers': 1, 'n_units_l0': 75, 'dropout_l0': 0.41410364351330586, 'optimizer': 'Adam', 'lr': 5.018356152252206e-05}. Best is trial 0 with value: 0.5782747603833865.\u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:58,091]\u001b[0m Trial 3 finished with value: 0.5782747603833865 and parameters: {'n_layers': 1, 'n_units_l0': 11, 'dropout_l0': 0.4982946263910813, 'optimizer': 'Adam', 'lr': 0.001097923047613219}. Best is trial 0 with value: 0.5782747603833865.\u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:59,073]\u001b[0m Trial 4 finished with value: 0.5782747603833865 and parameters: {'n_layers': 2, 'n_units_l0': 36, 'dropout_l0': 0.42310615629446513, 'n_units_l1': 47, 'dropout_l1': 0.3495039363410643, 'optimizer': 'Adam', 'lr': 0.0036829518162263815}. Best is trial 0 with value: 0.5782747603833865.\u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:59,120]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:59,132]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:59,147]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:59,194]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-05-25 16:54:59,246]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  10\n",
      "  Number of pruned trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value:  0.5782747603833865\n",
      "  Params: \n",
      "    n_layers: 3\n",
      "    n_units_l0: 34\n",
      "    dropout_l0: 0.3768938809309429\n",
      "    n_units_l1: 20\n",
      "    dropout_l1: 0.41453735681957093\n",
      "    n_units_l2: 59\n",
      "    dropout_l2: 0.3778615869451023\n",
      "    optimizer: SGD\n",
      "    lr: 0.0009460704260547728\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10, timeout=60)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "767c1bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5',\n",
       "       'PROC_10', 'wpr', 'sto_os', 'goog_trend_score', 'count', 'compound',\n",
       "       'retweets_count', 'Daily_Change_Perc', 'Close/Last_Gold', 'Open_Gold',\n",
       "       'Daily_Change_Gold', 'Close/Last_SP500', 'Open_SP500',\n",
       "       'Daily_Change_SP500'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "57e80cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_csv(\"bitcoin_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9b686836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       'Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5',\n",
       "       'PROC_10', 'wpr', 'sto_os', 'goog_trend_score', 'count', 'compound',\n",
       "       'retweets_count', 'likes_count', 'replies_count',\n",
       "       'compound_weighted_replies', 'compound_weighted_likes',\n",
       "       'compound_weighted_retweets', 'Daily_Change_Perc', 'Weekly_Change',\n",
       "       'Weekly_Change_Perc', 'Close/Last_Gold', 'Open_Gold',\n",
       "       'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold',\n",
       "       'Close/Last_SP500', 'Open_SP500', 'Daily_Change_SP500',\n",
       "       'Daily_Change_Perc_SP500', 'Increased_SP500', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc4a12ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "047c4a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Change</th>\n",
       "      <th>Daily_Change_Ind</th>\n",
       "      <th>MACD</th>\n",
       "      <th>...</th>\n",
       "      <th>Open_Gold</th>\n",
       "      <th>Daily_Change_Gold</th>\n",
       "      <th>Daily_Change_Perc_Gold</th>\n",
       "      <th>Increased_Gold</th>\n",
       "      <th>Close/Last_SP500</th>\n",
       "      <th>Open_SP500</th>\n",
       "      <th>Daily_Change_SP500</th>\n",
       "      <th>Daily_Change_Perc_SP500</th>\n",
       "      <th>Increased_SP500</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>4384.450195</td>\n",
       "      <td>4403.930176</td>\n",
       "      <td>4224.640137</td>\n",
       "      <td>4382.660156</td>\n",
       "      <td>1959330048</td>\n",
       "      <td>-0.219727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.734756</td>\n",
       "      <td>...</td>\n",
       "      <td>1297.6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.013641</td>\n",
       "      <td>1</td>\n",
       "      <td>2444.24</td>\n",
       "      <td>2447.35</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>563</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>972.018982</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>970.403015</td>\n",
       "      <td>164582000</td>\n",
       "      <td>50.020996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.846431</td>\n",
       "      <td>...</td>\n",
       "      <td>1197.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>1</td>\n",
       "      <td>2278.87</td>\n",
       "      <td>2274.02</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>9271.329102</td>\n",
       "      <td>9793.268555</td>\n",
       "      <td>9255.035156</td>\n",
       "      <td>9733.721680</td>\n",
       "      <td>56426907637</td>\n",
       "      <td>463.734375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>491.284984</td>\n",
       "      <td>...</td>\n",
       "      <td>1723.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>1</td>\n",
       "      <td>2852.50</td>\n",
       "      <td>2794.54</td>\n",
       "      <td>57.96</td>\n",
       "      <td>0.020740</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>2014-11-10</td>\n",
       "      <td>362.265015</td>\n",
       "      <td>374.816010</td>\n",
       "      <td>357.561005</td>\n",
       "      <td>366.924011</td>\n",
       "      <td>30450100</td>\n",
       "      <td>3.660003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.684871</td>\n",
       "      <td>...</td>\n",
       "      <td>1176.8</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-0.014446</td>\n",
       "      <td>0</td>\n",
       "      <td>2038.26</td>\n",
       "      <td>2032.01</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>944</td>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>7062.939941</td>\n",
       "      <td>7166.549805</td>\n",
       "      <td>6890.540039</td>\n",
       "      <td>6951.799805</td>\n",
       "      <td>3925900000</td>\n",
       "      <td>-116.680175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.940525</td>\n",
       "      <td>...</td>\n",
       "      <td>1214.4</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>-0.004776</td>\n",
       "      <td>0</td>\n",
       "      <td>2850.40</td>\n",
       "      <td>2840.29</td>\n",
       "      <td>10.11</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date         Open         High          Low        Close  \\\n",
       "0         708  2017-08-28  4384.450195  4403.930176  4224.640137  4382.660156   \n",
       "1         563  2017-01-31   920.958984   972.018982   920.958984   970.403015   \n",
       "2        1390  2020-05-14  9271.329102  9793.268555  9255.035156  9733.721680   \n",
       "3          19  2014-11-10   362.265015   374.816010   357.561005   366.924011   \n",
       "4         944  2018-08-06  7062.939941  7166.549805  6890.540039  6951.799805   \n",
       "\n",
       "        Volume  Daily_Change  Daily_Change_Ind        MACD  ...  Open_Gold  \\\n",
       "0   1959330048     -0.219727               0.0  318.734756  ...     1297.6   \n",
       "1    164582000     50.020996               1.0   12.846431  ...     1197.7   \n",
       "2  56426907637    463.734375               1.0  491.284984  ...     1723.1   \n",
       "3     30450100      3.660003               1.0   -5.684871  ...     1176.8   \n",
       "4   3925900000   -116.680175               0.0   55.940525  ...     1214.4   \n",
       "\n",
       "   Daily_Change_Gold  Daily_Change_Perc_Gold  Increased_Gold  \\\n",
       "0               17.7                0.013641               1   \n",
       "1               13.7                0.011439               1   \n",
       "2               17.8                0.010330               1   \n",
       "3              -17.0               -0.014446               0   \n",
       "4               -5.8               -0.004776               0   \n",
       "\n",
       "   Close/Last_SP500  Open_SP500  Daily_Change_SP500  Daily_Change_Perc_SP500  \\\n",
       "0           2444.24     2447.35               -3.11                -0.001271   \n",
       "1           2278.87     2274.02                4.85                 0.002133   \n",
       "2           2852.50     2794.54               57.96                 0.020740   \n",
       "3           2038.26     2032.01                6.25                 0.003076   \n",
       "4           2850.40     2840.29               10.11                 0.003559   \n",
       "\n",
       "   Increased_SP500  label  \n",
       "0                0    1.0  \n",
       "1                1    1.0  \n",
       "2                1    0.0  \n",
       "3                1    1.0  \n",
       "4                1    0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea45dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
