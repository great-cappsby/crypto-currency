{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix #classification_report, plot_roc_curve, plot_precision_recall_curve \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from functools import partial\n",
    "#import plotly\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Use all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Change</th>\n",
       "      <th>Daily_Change_Ind</th>\n",
       "      <th>MACD</th>\n",
       "      <th>...</th>\n",
       "      <th>Daily_Change_Perc_Gold</th>\n",
       "      <th>Increased_Gold</th>\n",
       "      <th>RSI_Gold</th>\n",
       "      <th>Close/Last_SP500</th>\n",
       "      <th>Open_SP500</th>\n",
       "      <th>Daily_Change_SP500</th>\n",
       "      <th>Daily_Change_Perc_SP500</th>\n",
       "      <th>Increased_SP500</th>\n",
       "      <th>RSI_SP500</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>371.437012</td>\n",
       "      <td>382.363007</td>\n",
       "      <td>370.382996</td>\n",
       "      <td>377.321014</td>\n",
       "      <td>71701600</td>\n",
       "      <td>6.027008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.296558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>1</td>\n",
       "      <td>33.968948</td>\n",
       "      <td>2080.41</td>\n",
       "      <td>2090.95</td>\n",
       "      <td>-10.54</td>\n",
       "      <td>-0.005041</td>\n",
       "      <td>0</td>\n",
       "      <td>57.384705</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1016</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>5736.149902</td>\n",
       "      <td>5774.819824</td>\n",
       "      <td>5358.379883</td>\n",
       "      <td>5648.029785</td>\n",
       "      <td>7032140000</td>\n",
       "      <td>-90.320313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-121.126607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>1</td>\n",
       "      <td>48.296230</td>\n",
       "      <td>2730.20</td>\n",
       "      <td>2693.52</td>\n",
       "      <td>36.68</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>1</td>\n",
       "      <td>59.599184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1144</td>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>7677.269043</td>\n",
       "      <td>7943.791504</td>\n",
       "      <td>7533.196777</td>\n",
       "      <td>7881.846680</td>\n",
       "      <td>24457107820</td>\n",
       "      <td>201.780274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>625.729133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>1</td>\n",
       "      <td>53.162762</td>\n",
       "      <td>2822.24</td>\n",
       "      <td>2836.70</td>\n",
       "      <td>-14.46</td>\n",
       "      <td>-0.005097</td>\n",
       "      <td>0</td>\n",
       "      <td>41.547984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082</td>\n",
       "      <td>2019-02-25</td>\n",
       "      <td>3807.002441</td>\n",
       "      <td>3913.707275</td>\n",
       "      <td>3807.002441</td>\n",
       "      <td>3882.696289</td>\n",
       "      <td>9318796067</td>\n",
       "      <td>72.268799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.876946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>0</td>\n",
       "      <td>58.979842</td>\n",
       "      <td>2796.11</td>\n",
       "      <td>2804.35</td>\n",
       "      <td>-8.24</td>\n",
       "      <td>-0.002938</td>\n",
       "      <td>0</td>\n",
       "      <td>45.563129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1149</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>8320.286133</td>\n",
       "      <td>8586.659180</td>\n",
       "      <td>8172.550781</td>\n",
       "      <td>8574.501953</td>\n",
       "      <td>25365190957</td>\n",
       "      <td>255.029297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608.732748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>1</td>\n",
       "      <td>63.288965</td>\n",
       "      <td>2752.06</td>\n",
       "      <td>2766.15</td>\n",
       "      <td>-14.09</td>\n",
       "      <td>-0.005094</td>\n",
       "      <td>0</td>\n",
       "      <td>20.448755</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date         Open         High          Low        Close  \\\n",
       "0         268  2015-11-30   371.437012   382.363007   370.382996   377.321014   \n",
       "1        1016  2018-11-15  5736.149902  5774.819824  5358.379883  5648.029785   \n",
       "2        1144  2019-05-23  7677.269043  7943.791504  7533.196777  7881.846680   \n",
       "3        1082  2019-02-25  3807.002441  3913.707275  3807.002441  3882.696289   \n",
       "4        1149  2019-05-31  8320.286133  8586.659180  8172.550781  8574.501953   \n",
       "\n",
       "        Volume  Daily_Change  Daily_Change_Ind        MACD  ...  \\\n",
       "0     71701600      6.027008               1.0   10.296558  ...   \n",
       "1   7032140000    -90.320313               0.0 -121.126607  ...   \n",
       "2  24457107820    201.780274               1.0  625.729133  ...   \n",
       "3   9318796067     72.268799               1.0   94.876946  ...   \n",
       "4  25365190957    255.029297               1.0  608.732748  ...   \n",
       "\n",
       "   Daily_Change_Perc_Gold  Increased_Gold   RSI_Gold  Close/Last_SP500  \\\n",
       "0                0.008807               1  33.968948           2080.41   \n",
       "1                0.002641               1  48.296230           2730.20   \n",
       "2                0.009777               1  53.162762           2822.24   \n",
       "3               -0.001802               0  58.979842           2796.11   \n",
       "4                0.013842               1  63.288965           2752.06   \n",
       "\n",
       "   Open_SP500  Daily_Change_SP500  Daily_Change_Perc_SP500  Increased_SP500  \\\n",
       "0     2090.95              -10.54                -0.005041                0   \n",
       "1     2693.52               36.68                 0.013618                1   \n",
       "2     2836.70              -14.46                -0.005097                0   \n",
       "3     2804.35               -8.24                -0.002938                0   \n",
       "4     2766.15              -14.09                -0.005094                0   \n",
       "\n",
       "   RSI_SP500  label  \n",
       "0  57.384705    0.0  \n",
       "1  59.599184    0.0  \n",
       "2  41.547984    1.0  \n",
       "3  45.563129    0.0  \n",
       "4  20.448755    0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv(\"bitcoin_train.csv\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5', 'PROC_10', 'wpr', 'sto_os', 'goog_trend_score', 'retweets_count', 'likes_count', 'replies_count', 'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', 'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500', 'compound_weighted', 'compound_weighted_avg7', 'compound_weighted_daily_diff', 'compound_weighted_weekly_diff', 'replies_count_daily_diff', 'replies_count_avg7', 'replies_count_weekly_diff', 'count', 'count_daily_diff', 'count_weekly_diff']\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "features_df.columns\n",
    "\n",
    "feature_lst = ['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5','PROC_10', 'wpr',\\\n",
    "                'sto_os', 'goog_trend_score', 'retweets_count', 'likes_count', \\\n",
    "                'replies_count', 'Daily_Change_Perc', 'Daily_Change_Gold', \\\n",
    "                'Daily_Change_Perc_Gold', 'Increased_Gold', \\\n",
    "                'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500', \\\n",
    "                'compound_weighted', 'compound_weighted_avg7', \\\n",
    "                'compound_weighted_daily_diff' , 'compound_weighted_weekly_diff',\n",
    "                'replies_count_daily_diff', 'replies_count_avg7', 'replies_count_weekly_diff',\n",
    "                'count', 'count_daily_diff', 'count_weekly_diff']\n",
    "\n",
    "outcome = features_df.columns[-1]\n",
    "\n",
    "print(feature_lst)\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1246, 29) (1246,)\n"
     ]
    }
   ],
   "source": [
    "X = features_df[feature_lst]\n",
    "y = features_df[outcome]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "Trying hyperparameter tuning (OPTUNA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING OPTUNA TO CHOOSE BEST HYPERPARAMETERS\n",
    "def objective(trial:Trial, train = None, labels = None, val = None, val_labels = None):\n",
    "    ada_m_depth = trial.suggest_int(\"max_depth\", 1, 5, step = 1)\n",
    "    ada_n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000, step = 50)\n",
    "    ada_learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1.0, step = .009)\n",
    "\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = ada_m_depth, random_state = 1234)\n",
    "    ada_clf = AdaBoostClassifier(base_estimator, \n",
    "                                n_estimators = ada_n_estimators,\n",
    "                                learning_rate = ada_learning_rate,\n",
    "                                algorithm = \"SAMME.R\",\n",
    "                                random_state = 1234)\n",
    "\n",
    "\n",
    "    X = features_df[feature_lst]\n",
    "    y = features_df[outcome]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 1234)                          \n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    accuracy = ada_clf.score(X_valid, y_valid)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from optuna.samplers import TPESampler\n",
    "# sampler2 = TPESampler(seed=10) \n",
    "# study = optuna.create_study(direction ='maximize', sampler=optuna.samplers.RandomSampler(seed=123))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.5352564102564102\n",
      "Best Params: \n",
      "  max_depth: 4\n",
      "  n_estimators: 850\n",
      "  learning_rate: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# study.optimize((objective), n_trials=20,n_jobs=-1)\n",
    "\n",
    "# trial = study.best_trial\n",
    "# print(\"Best Score: \", trial.value)\n",
    "# print(\"Best Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(\"  {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run models with hyperparameters from optuna on \n",
    "base_estimator = DecisionTreeClassifier(max_depth = 1, random_state = 1234)\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = 200,\n",
    "                              learning_rate = 0.43, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5192307692307693\n",
      "MSE: 0.4807692307692308\n",
      "CONFUSION: [[ 56  85]\n",
      " [ 65 106]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of what Ana suggested\n",
    "\n",
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a regular decision tree model with different tree depth, \n",
    "use as comparison to show that adaboost is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Figure out what the tree depth should be (maximum score)\n",
    "# results_dict = {}\n",
    "# cx_validation = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "# for depth in range(1, 11):\n",
    "#     base_estimator = DecisionTreeClassifier(max_depth = depth, random_state = 1234)\n",
    "#     if base_estimator.fit(X_train,y_train).tree_.max_depth < depth:\n",
    "#         break\n",
    "#     accuracy_score = np.mean(cross_val_score(base_estimator, X, y, cv = cx_validation, scoring = 'accuracy', n_jobs = 1))\n",
    "#     print(\"Depth:\", depth, \", Score:\", accuracy_score)\n",
    "\n",
    "#     results_dict[depth] = accuracy_score\n",
    "\n",
    "# max_val = -1\n",
    "# max_depth_val = None\n",
    "# for key, val in results_dict.items():\n",
    "#     if val > max_val:\n",
    "#         max_val = val\n",
    "#         max_depth_val = key\n",
    "\n",
    "# print(\"Max depth should be:\", max_depth_val)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight run of the model with default chosen n_estimators and learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create adaboost classifer object\n",
    "# base_estimator = DecisionTreeClassifier(max_depth = 2, random_state = 1234)\n",
    "\n",
    "# adaboost = AdaBoostClassifier(base_estimator = base_estimator, random_state = 1234)\n",
    "\n",
    "# # Train Adaboost Classifer\n",
    "# adaboost.fit(X_train, y_train)\n",
    "\n",
    "# # Predict the response for valid dataset\n",
    "# y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Accuracy with chosen decision tree depth and randomly chosen hyperparameters\n",
    "# accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "# mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "# confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "# print(\"Accuracy:\", accuracy_score)\n",
    "# print(\"MSE:\", mse)\n",
    "# print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_import = adaboost.feature_importances_\n",
    "# for i in range(len(feature_lst)):\n",
    "#     print(f\"{feature_lst[i]}: {feature_import[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper parametertuning (number estimators and learning rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuning n_estimators and learning_Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "\n",
    "# parameters = {'base_estimator__max_depth':[1,5],\n",
    "#               'n_estimators':[10,50,500,1000],\n",
    "#               'learning_rate':[0.01,0.1]}\n",
    "# cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1234)\n",
    "# grid_result = GridSearchCV(abc, parameters,verbose=3,cv=cv,scoring='accuracy',n_jobs=-1)\n",
    "# grid_result.fit(X_train,y_train)\n",
    "\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# # summarize all scores that were evaluated\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "\n",
    "# mean_results = []\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "#     mean_results.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.556741 using {'base_estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.546995 (0.038835) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.01, 'n_estimators': 10}\n",
      "0.546633 (0.038238) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.553786 (0.035705) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.556696 (0.038027) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.553157 (0.040804) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.551293 (0.037687) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.555258 (0.040110) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.550278 (0.041876) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.556741 (0.042333) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.541749 (0.038635) with: {'base_estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "0.550930 (0.052019) with: {'base_estimator__max_depth': 1, 'learning_rate': 1, 'n_estimators': 10}\n",
      "0.554610 (0.043622) with: {'base_estimator__max_depth': 1, 'learning_rate': 1, 'n_estimators': 50}\n",
      "0.540010 (0.037757) with: {'base_estimator__max_depth': 1, 'learning_rate': 1, 'n_estimators': 100}\n",
      "0.525326 (0.043682) with: {'base_estimator__max_depth': 1, 'learning_rate': 1, 'n_estimators': 500}\n",
      "0.524609 (0.043744) with: {'base_estimator__max_depth': 1, 'learning_rate': 1, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    "\n",
    "# alternative way to check n_estiamtors and learning_Rate\n",
    "model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "\n",
    "param_grids  = {'base_estimator__max_depth':[i for i in range(1,2,5)],\n",
    "              'n_estimators':[10,50,100,500,1000],\n",
    "              'learning_rate':[0.01,0.1, 1]}\n",
    "\n",
    "\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1234)\n",
    "\n",
    "# define the grid search procedure\n",
    "#grid_search = GridSearchCV(estimator = model, param_grid = grid, n_jobs = -1, cv = cv, scoring = 'accuracy')\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grids, n_jobs = -1, cv = cv, scoring = 'accuracy')\n",
    "# execute the grid search\n",
    "\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "#print(\"ARE WE HERE\")\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "mean_results = []\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    mean_results.append(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun adaboost with chosen hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_n: 500\n",
      "chosen_learning_rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "chosen_depth = list(grid_result.best_params_.values())[0]\n",
    "chosen_learning_rate = list(grid_result.best_params_.values())[1]\n",
    "chosen_n = list(grid_result.best_params_.values())[2]\n",
    "print(\"chosen_n:\", chosen_n)\n",
    "print(\"chosen_learning_rate:\", chosen_learning_rate)\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth = chosen_depth, random_state = 1234)\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = chosen_n,\n",
    "                              learning_rate = chosen_learning_rate, random_state = 1234)\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4935897435897436\n",
      "CONFUSION: [[ 43  98]\n",
      " [ 60 111]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 43  98]\n",
      " [ 60 111]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(adaboost, X_valid, y_valid)\n",
    "print(metrics.confusion_matrix(y_valid, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily_Change: 0.024\n",
      "Daily_Change_Ind: 0.0\n",
      "MACD: 0.098\n",
      "PROC_3: 0.03\n",
      "PROC_5: 0.022\n",
      "PROC_10: 0.054\n",
      "wpr: 0.038\n",
      "sto_os: 0.046\n",
      "goog_trend_score: 0.03\n",
      "retweets_count: 0.038\n",
      "likes_count: 0.002\n",
      "replies_count: 0.028\n",
      "Daily_Change_Perc: 0.02\n",
      "Daily_Change_Gold: 0.01\n",
      "Daily_Change_Perc_Gold: 0.028\n",
      "Increased_Gold: 0.0\n",
      "Daily_Change_SP500: 0.032\n",
      "Daily_Change_Perc_SP500: 0.024\n",
      "Increased_SP500: 0.0\n",
      "compound_weighted: 0.042\n",
      "compound_weighted_avg7: 0.046\n",
      "compound_weighted_daily_diff: 0.044\n",
      "compound_weighted_weekly_diff: 0.038\n",
      "replies_count_daily_diff: 0.05\n",
      "replies_count_avg7: 0.094\n",
      "replies_count_weekly_diff: 0.052\n",
      "count: 0.002\n",
      "count_daily_diff: 0.038\n",
      "count_weekly_diff: 0.07\n"
     ]
    }
   ],
   "source": [
    "feature_import = adaboost.feature_importances_\n",
    "for i in range(len(feature_lst)):\n",
    "    print(f\"{feature_lst[i]}: {feature_import[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for Financial variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for Dogecoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogecoin = pd.read_csv(\"dogecoin_train.csv\")\n",
    "dogecoin = dogecoin.rename(columns={'goog_trend': 'goog_trend_score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dog = dogecoin[feature_lst]\n",
    "y_dog = dogecoin['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_dog, y_dog, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial:Trial, train = None, labels = None, val = None, val_labels = None, val_rets = None):\n",
    "    ada_m_depth = trial.suggest_int(\"max_depth\", 1, 5, step = 1)\n",
    "    ada_n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000, step = 50)\n",
    "    ada_learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1.0, step = .009)\n",
    "\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = ada_m_depth, random_state = 1234)\n",
    "    ada_clf = AdaBoostClassifier(base_estimator, \n",
    "                                n_estimators = ada_n_estimators,\n",
    "                                learning_rate = ada_learning_rate,\n",
    "                                algorithm = \"SAMME.R\")\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    accuracy = ada_clf.score(X_valid, y_valid)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction = \"maximize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials = 20, n_jobs = -1)\n",
    "\n",
    "\n",
    "trial = study.best_trial\n",
    "print(\"Best Score: \", trial.value)\n",
    "print(\"Best Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"  {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth = 2, random_state = 1234)\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = 250,\n",
    "                              learning_rate = 0.001, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1 , Score: 0.5232000000000001\n",
      "Depth: 2 , Score: 0.5119999999999999\n",
      "Depth: 3 , Score: 0.5176000000000001\n",
      "Depth: 4 , Score: 0.5216\n",
      "Depth: 5 , Score: 0.5192\n",
      "Depth: 6 , Score: 0.5199999999999999\n",
      "Depth: 7 , Score: 0.5008000000000001\n",
      "Depth: 8 , Score: 0.5040000000000001\n",
      "Depth: 9 , Score: 0.5104000000000001\n",
      "Depth: 10 , Score: 0.4952\n",
      "Max depth should be: 1\n"
     ]
    }
   ],
   "source": [
    "# Figure out what the tree depth should be (maximum score)\n",
    "results_dict = {}\n",
    "cx_validation = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "for depth in range(1, 11):\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = depth, random_state = 1234)\n",
    "    if base_estimator.fit(X_train,y_train).tree_.max_depth < depth:\n",
    "        break\n",
    "    accuracy_score = np.mean(cross_val_score(base_estimator, X, y, cv = cx_validation, scoring = 'accuracy', n_jobs = 1))\n",
    "    print(\"Depth:\", depth, \", Score:\", accuracy_score)\n",
    "\n",
    "    results_dict[depth] = accuracy_score\n",
    "\n",
    "max_val = -1\n",
    "max_depth_val = None\n",
    "for key, val in results_dict.items():\n",
    "    if val > max_val:\n",
    "        max_val = val\n",
    "        max_depth_val = key\n",
    "\n",
    "print(\"Max depth should be:\", max_depth_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "base_estimator = DecisionTreeClassifier(max_depth = 1, random_state = 1234)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7835365853658537\n",
      "MSE: 0.21646341463414634\n",
      "CONFUSION: [[239  22]\n",
      " [ 49  18]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and randomly chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily_Change: 0.1\n",
      "Daily_Change_Ind: 0.0\n",
      "MACD: 0.12\n",
      "PROC_3: 0.04\n",
      "PROC_5: 0.04\n",
      "PROC_10: 0.04\n",
      "wpr: 0.08\n",
      "sto_os: 0.02\n",
      "goog_trend_score: 0.12\n",
      "count: 0.0\n",
      "compound: 0.02\n",
      "retweets_count: 0.0\n",
      "likes_count: 0.04\n",
      "replies_count: 0.02\n",
      "compound_weighted_replies: 0.04\n",
      "compound_weighted_likes: 0.0\n",
      "compound_weighted_retweets: 0.02\n",
      "Daily_Change_Perc: 0.02\n",
      "Daily_Change_Gold: 0.1\n",
      "Daily_Change_Perc_Gold: 0.1\n",
      "Increased_Gold: 0.0\n",
      "Daily_Change_SP500: 0.08\n",
      "Daily_Change_Perc_SP500: 0.0\n",
      "Increased_SP500: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_import = adaboost.feature_importances_\n",
    "for i in range(len(feature_lst)):\n",
    "    print(f\"{feature_lst[i]}: {feature_import[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper parametertuning (number estimators and learning rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.805308 using {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 500}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.802584 (0.008477) with: {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.803278 (0.019011) with: {'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.802244 (0.008115) with: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.802261 (0.018886) with: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.788332 (0.023875) with: {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.786965 (0.026138) with: {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "0.791040 (0.027376) with: {'learning_rate': 1.0, 'n_estimators': 10}\n",
      "0.788655 (0.027200) with: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.782557 (0.031643) with: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.776775 (0.034145) with: {'learning_rate': 1.0, 'n_estimators': 500}\n",
      "0.765227 (0.034400) with: {'learning_rate': 1.0, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid, n_jobs = -1, cv = cv, scoring = 'accuracy')\n",
    "\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun adaboost with chosen hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_n: 10\n",
      "chosen_learing_rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth = 1, random_state = 1234)\n",
    "\n",
    "chosen_learning_rate = list(grid_result.best_params_.values())[0]\n",
    "chosen_n = list(grid_result.best_params_.values())[1]\n",
    "\n",
    "print(\"chosen_n:\", chosen_n)\n",
    "print(\"chosen_learing_rate:\", chosen_learning_rate)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = chosen_n,\n",
    "                              learning_rate = chosen_learning_rate, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7957317073170732\n",
      "MSE: 0.20426829268292682\n",
      "CONFUSION: [[261   0]\n",
      " [ 67   0]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[261   0]\n",
      " [ 67   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(adaboost, X_valid, y_valid)\n",
    "print(metrics.confusion_matrix(y_valid, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily_Change: 0.0\n",
      "Daily_Change_Ind: 0.0\n",
      "MACD: 1.0\n",
      "PROC_3: 0.0\n",
      "PROC_5: 0.0\n",
      "PROC_10: 0.0\n",
      "wpr: 0.0\n",
      "sto_os: 0.0\n",
      "goog_trend_score: 0.0\n",
      "count: 0.0\n",
      "compound: 0.0\n",
      "retweets_count: 0.0\n",
      "likes_count: 0.0\n",
      "replies_count: 0.0\n",
      "compound_weighted_replies: 0.0\n",
      "compound_weighted_likes: 0.0\n",
      "compound_weighted_retweets: 0.0\n",
      "Daily_Change_Perc: 0.0\n",
      "Daily_Change_Gold: 0.0\n",
      "Daily_Change_Perc_Gold: 0.0\n",
      "Increased_Gold: 0.0\n",
      "Daily_Change_SP500: 0.0\n",
      "Daily_Change_Perc_SP500: 0.0\n",
      "Increased_SP500: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_import = adaboost.feature_importances_\n",
    "for i in range(len(feature_lst)):\n",
    "    print(f\"{feature_lst[i]}: {feature_import[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------\n",
    "Repeat with fewer attributes\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first do bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5', 'PROC_10', 'wpr', 'sto_os', 'goog_trend_score', 'count', 'retweets_count', 'likes_count', 'replies_count', 'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', 'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500']\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "features_df.columns\n",
    "\n",
    "features_lst = ['MACD', 'RSI', 'PROC_3', 'Daily_Change_Perc_SP500', 'Daily_Change_Perc_Gold', \\\n",
    "                'compound_weighted_avg7', 'likes_count_daily_diff', 'pos_weighted_avg7',\\\n",
    "                'retweets_count_weekly_diff','goog_trend_score']\n",
    "\n",
    "outcome = features_df.columns[-1]\n",
    "\n",
    "print(feature_lst)\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1246, 20) (1246,)\n"
     ]
    }
   ],
   "source": [
    "X = features_df[feature_lst]\n",
    "y = features_df[outcome]\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial:Trial, train = None, labels = None, val = None, val_labels = None):\n",
    "    ada_m_depth = trial.suggest_int(\"max_depth\", 1, 5, step = 1)\n",
    "    ada_n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000, step = 50)\n",
    "    ada_learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1.0, step = .009)\n",
    "\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = ada_m_depth, random_state = 1234)\n",
    "    ada_clf = AdaBoostClassifier(base_estimator, \n",
    "                                n_estimators = ada_n_estimators,\n",
    "                                learning_rate = ada_learning_rate,\n",
    "                                algorithm = \"SAMME.R\")\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    accuracy = ada_clf.score(X_valid, y_valid)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.5352564102564102\n",
      "Best Params: \n",
      "  max_depth: 3\n",
      "  n_estimators: 150\n",
      "  learning_rate: 0.8649999999999999\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\")\n",
    "study.optimize(objective, n_trials = 20, n_jobs = -1)\n",
    "\n",
    "trial = study.best_trial\n",
    "print(\"Best Score: \", trial.value)\n",
    "print(\"Best Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"  {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth = 2, random_state = 1234)\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = 250,\n",
    "                              learning_rate = 0.001, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5416666666666666\n",
      "MSE: 0.4583333333333333\n",
      "CONFUSION: [[ 62  79]\n",
      " [ 64 107]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.577156 using {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.558270 (0.046790) with: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "0.558270 (0.046790) with: {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "0.558270 (0.046790) with: {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "0.556486 (0.046447) with: {'learning_rate': 0.001, 'n_estimators': 500}\n",
      "0.559677 (0.046496) with: {'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "0.558270 (0.046790) with: {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "0.556128 (0.045798) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.560036 (0.046449) with: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.563967 (0.049997) with: {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.572886 (0.051213) with: {'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.563959 (0.043869) with: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.569675 (0.049124) with: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.577156 (0.051566) with: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.565694 (0.052309) with: {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.555659 (0.046494) with: {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "0.557519 (0.050688) with: {'learning_rate': 1.0, 'n_estimators': 10}\n",
      "0.558930 (0.056309) with: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.549245 (0.052923) with: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.530695 (0.051016) with: {'learning_rate': 1.0, 'n_estimators': 500}\n",
      "0.518630 (0.050345) with: {'learning_rate': 1.0, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    "\n",
    "# alternative way to check n_estiamtors and learning_Rate\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid, n_jobs = -1, cv = cv, scoring = 'accuracy')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "mean_results = []\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    mean_results.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "base_estimator = DecisionTreeClassifier(max_depth = 2, random_state = 1234)\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, random_state = 1234)\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47115384615384615\n",
      "MSE: 0.5288461538461539\n",
      "CONFUSION: [[53 88]\n",
      " [77 94]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily_Change: 0.06837026229462262\n",
      "Daily_Change_Ind: 0.0\n",
      "MACD: 0.0984933981907369\n",
      "PROC_3: 0.08124960788836638\n",
      "PROC_5: 0.05510786728617159\n",
      "PROC_10: 0.06006722592379675\n",
      "wpr: 0.044479782083094256\n",
      "sto_os: 0.04439830938995261\n",
      "goog_trend_score: 0.07085841939511693\n",
      "count: 0.037122684239862105\n",
      "retweets_count: 0.061018737499452774\n",
      "likes_count: 0.05253288451127324\n",
      "replies_count: 0.050023428685943665\n",
      "Daily_Change_Perc: 0.020446008740331485\n",
      "Daily_Change_Gold: 0.05330507295888297\n",
      "Daily_Change_Perc_Gold: 0.059561404144577515\n",
      "Increased_Gold: 0.0\n",
      "Daily_Change_SP500: 0.07252642244639963\n",
      "Daily_Change_Perc_SP500: 0.07043848432141858\n",
      "Increased_SP500: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_import = adaboost.feature_importances_\n",
    "for i in range(len(feature_lst)):\n",
    "    print(f\"{feature_lst[i]}: {feature_import[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat fewer vars for dogecoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogecoin = pd.read_csv(\"dogecoin_train.csv\")\n",
    "dogecoin = dogecoin.rename(columns={'goog_trend': 'goog_trend_score'})\n",
    "features_df.columns\n",
    "\n",
    "features_lst = ['MACD', 'RSI', 'PROC_3', 'Daily_Change_Perc_SP500', 'Daily_Change_Perc_Gold', \\\n",
    "                'compound_weighted_avg7', 'likes_count_daily_diff', 'pos_weighted_avg7',\\\n",
    "                'retweets_count_weekly_diff','goog_trend_score']\n",
    "\n",
    "outcome = features_df.columns[-1]\n",
    "X_dog = dogecoin[feature_lst]\n",
    "y_dog = dogecoin['label']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_dog, y_dog, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial:Trial, train = None, labels = None, val = None, val_labels = None, val_rets = None):\n",
    "    ada_m_depth = trial.suggest_int(\"max_depth\", 1, 5, step = 1)\n",
    "    ada_n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000, step = 50)\n",
    "    ada_learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1.0, step = .009)\n",
    "\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = ada_m_depth, random_state = 1234)\n",
    "    ada_clf = AdaBoostClassifier(base_estimator, \n",
    "                                n_estimators = ada_n_estimators,\n",
    "                                learning_rate = ada_learning_rate,\n",
    "                                algorithm = \"SAMME.R\")\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    accuracy = ada_clf.score(X_valid, y_valid)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7926829268292683\n",
      "Best Params: \n",
      "  max_depth: 4\n",
      "  n_estimators: 250\n",
      "  learning_rate: 0.9099999999999999\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\")\n",
    "study.optimize(objective, n_trials = 20, n_jobs = -1)\n",
    "\n",
    "\n",
    "trial = study.best_trial\n",
    "print(\"Best Score: \", trial.value)\n",
    "print(\"Best Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"  {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth = 2, random_state = 1234)\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = 250,\n",
    "                              learning_rate = 0.001, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7957317073170732\n",
      "MSE: 0.20426829268292682\n",
      "CONFUSION: [[256   5]\n",
      " [ 62   5]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.805308 using {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 500}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.802584 (0.008477) with: {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.804291 (0.018565) with: {'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.805308 (0.002443) with: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.802244 (0.008115) with: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.801580 (0.019279) with: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.795795 (0.019700) with: {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.788999 (0.024653) with: {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "0.792053 (0.028753) with: {'learning_rate': 1.0, 'n_estimators': 10}\n",
      "0.787291 (0.026957) with: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.788332 (0.030515) with: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.771353 (0.032597) with: {'learning_rate': 1.0, 'n_estimators': 500}\n",
      "0.761152 (0.037313) with: {'learning_rate': 1.0, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid, n_jobs = -1, cv = cv, scoring = 'accuracy')\n",
    "\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_n: 10\n",
      "chosen_learing_rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth = 1, random_state = 1234)\n",
    "\n",
    "chosen_learning_rate = list(grid_result.best_params_.values())[0]\n",
    "chosen_n = list(grid_result.best_params_.values())[1]\n",
    "\n",
    "print(\"chosen_n:\", chosen_n)\n",
    "print(\"chosen_learing_rate:\", chosen_learning_rate)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = chosen_n,\n",
    "                              learning_rate = chosen_learning_rate, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7957317073170732\n",
      "MSE: 0.20426829268292682\n",
      "CONFUSION: [[261   0]\n",
      " [ 67   0]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(adaboost, X_valid, y_valid)\n",
    "print(metrics.confusion_matrix(y_valid, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "# MISC OTHER CODE NOT USING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------\n",
    "We will evaluate the model using repeated stratified k-fold cross-validation, with three repeats and 10 folds. We will report the mean and standard deviation of the accuracy of the model across all repeats and folds.\n",
    "\n",
    "https://machinelearningmastery.com/adaboost-ensemble-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.635 (0.053)\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1234)\n",
    "n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This achieved 63.5% accuracy with default hyperparameters. Now make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7070063694267515\n",
      "MSE: 0.2929936305732484\n",
      "CONFUSION: [[ 91  45]\n",
      " [ 47 131]]\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X_train, y_train)\n",
    "# make a single prediction\n",
    "y_hat = model.predict(X_valid)\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "                   base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                         random_state=1234),\n",
       "                   n_estimators=3, random_state=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth=3, random_state=1234)\n",
    "adaboost = AdaBoostClassifier(base_estimator=base_estimator,\n",
    "                              n_estimators=3, algorithm=\"SAMME\",\n",
    "                              random_state=0)\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for boosting_round, tree in enumerate(adaboost.estimators_):\n",
    "    plt.figure()\n",
    "    # we convert `data` into a NumPy array to avoid a warning raised in scikit-learn\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        tree, X_train.to_numpy(), response_method=\"predict\", cmap=\"RdBu\", alpha=0.5\n",
    "    )\n",
    "    sns.scatterplot(x=culmen_columns[0], y=culmen_columns[1],\n",
    "                    hue=target_column, data=penguins,\n",
    "                    palette=palette)\n",
    "    plt.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\")\n",
    "    _ = plt.title(f\"Decision tree trained at round {boosting_round}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parametertuning (number estimators and learning rate)\n",
    "# ada = AdaBoostClassifier()\n",
    "# search_grid = {'n_estimators':[500,1000,2000], 'learning_rate':[.001,0.01,.1]}\n",
    "# search = GridSearchCV(estimator = ada, param_grid = search_grid, scoring = 'accuracy', n_jobs = 1, cv = cx_validation)\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/\n",
    "\n",
    "# search.fit(X,y)\n",
    "# search.best_params_\n",
    "# print(search.best_params_)\n",
    "# search.best_score_\n",
    "# print(search.best_score_)\n",
    "#Out[34]: 0.7425149700598802\n",
    "\n",
    "\n",
    "\n",
    "# https://python-bloggers.com/2019/01/adaboost-classification-in-python/\n",
    "\n",
    "# score = np.mean(cross_val_score(ada, X, y, scoring='accuracy', cv = cx_validation, n_jobs = 1))\n",
    "# score\n",
    "\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/\n",
    "\n",
    "# AdaBoostClassifier.get_params().keys()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
