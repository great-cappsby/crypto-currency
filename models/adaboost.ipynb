{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Change</th>\n",
       "      <th>Daily_Change_Ind</th>\n",
       "      <th>MACD</th>\n",
       "      <th>...</th>\n",
       "      <th>Open_Gold</th>\n",
       "      <th>Daily_Change_Gold</th>\n",
       "      <th>Daily_Change_Perc_Gold</th>\n",
       "      <th>Increased_Gold</th>\n",
       "      <th>Close/Last_SP500</th>\n",
       "      <th>Open_SP500</th>\n",
       "      <th>Daily_Change_SP500</th>\n",
       "      <th>Daily_Change_Perc_SP500</th>\n",
       "      <th>Increased_SP500</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>15864.099609</td>\n",
       "      <td>15888.400391</td>\n",
       "      <td>13937.299805</td>\n",
       "      <td>14606.500000</td>\n",
       "      <td>12336499712</td>\n",
       "      <td>-1232.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636.405515</td>\n",
       "      <td>...</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>1</td>\n",
       "      <td>2687.54</td>\n",
       "      <td>2686.10</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>908</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>6342.750000</td>\n",
       "      <td>6707.140137</td>\n",
       "      <td>6334.459961</td>\n",
       "      <td>6675.350098</td>\n",
       "      <td>5138710016</td>\n",
       "      <td>325.450196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-383.201570</td>\n",
       "      <td>...</td>\n",
       "      <td>1303.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>1</td>\n",
       "      <td>2782.49</td>\n",
       "      <td>2783.21</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224</td>\n",
       "      <td>2015-09-25</td>\n",
       "      <td>234.362000</td>\n",
       "      <td>237.427002</td>\n",
       "      <td>233.684006</td>\n",
       "      <td>235.143997</td>\n",
       "      <td>22363600</td>\n",
       "      <td>0.614990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.731076</td>\n",
       "      <td>...</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-0.004692</td>\n",
       "      <td>0</td>\n",
       "      <td>1931.34</td>\n",
       "      <td>1935.93</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1042</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>3819.666748</td>\n",
       "      <td>3893.359619</td>\n",
       "      <td>3769.863770</td>\n",
       "      <td>3857.297607</td>\n",
       "      <td>5326547918</td>\n",
       "      <td>41.806884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-83.043066</td>\n",
       "      <td>...</td>\n",
       "      <td>1273.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0</td>\n",
       "      <td>2467.70</td>\n",
       "      <td>2363.12</td>\n",
       "      <td>104.58</td>\n",
       "      <td>0.044255</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>563</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>972.018982</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>970.403015</td>\n",
       "      <td>164582000</td>\n",
       "      <td>50.020996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.846431</td>\n",
       "      <td>...</td>\n",
       "      <td>1197.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>1</td>\n",
       "      <td>2278.87</td>\n",
       "      <td>2274.02</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date          Open          High           Low  \\\n",
       "0         793  2017-12-28  15864.099609  15888.400391  13937.299805   \n",
       "1         908  2018-06-14   6342.750000   6707.140137   6334.459961   \n",
       "2         224  2015-09-25    234.362000    237.427002    233.684006   \n",
       "3        1042  2018-12-26   3819.666748   3893.359619   3769.863770   \n",
       "4         563  2017-01-31    920.958984    972.018982    920.958984   \n",
       "\n",
       "          Close       Volume  Daily_Change  Daily_Change_Ind        MACD  ...  \\\n",
       "0  14606.500000  12336499712  -1232.000000               0.0  636.405515  ...   \n",
       "1   6675.350098   5138710016    325.450196               1.0 -383.201570  ...   \n",
       "2    235.143997     22363600      0.614990               1.0   -1.731076  ...   \n",
       "3   3857.297607   5326547918     41.806884               1.0  -83.043066  ...   \n",
       "4    970.403015    164582000     50.020996               1.0   12.846431  ...   \n",
       "\n",
       "   Open_Gold  Daily_Change_Gold  Daily_Change_Perc_Gold  Increased_Gold  \\\n",
       "0     1292.0                5.2                0.004025               1   \n",
       "1     1303.1                5.2                0.003990               1   \n",
       "2     1151.0               -5.4               -0.004692               0   \n",
       "3     1273.5               -0.5               -0.000393               0   \n",
       "4     1197.7               13.7                0.011439               1   \n",
       "\n",
       "   Close/Last_SP500  Open_SP500  Daily_Change_SP500  Daily_Change_Perc_SP500  \\\n",
       "0           2687.54     2686.10                1.44                 0.000536   \n",
       "1           2782.49     2783.21               -0.72                -0.000259   \n",
       "2           1931.34     1935.93               -4.59                -0.002371   \n",
       "3           2467.70     2363.12              104.58                 0.044255   \n",
       "4           2278.87     2274.02                4.85                 0.002133   \n",
       "\n",
       "   Increased_SP500  label  \n",
       "0                1    0.0  \n",
       "1                0    0.0  \n",
       "2                0    1.0  \n",
       "3                1    1.0  \n",
       "4                1    1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv(\"bitcoin_train.csv\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5', 'PROC_10', 'wpr', 'sto_os', 'goog_trend_score', 'count', 'compound', 'retweets_count', 'likes_count', 'replies_count', 'compound_weighted_replies', 'compound_weighted_likes', 'compound_weighted_retweets', 'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', 'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500']\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "features_df.columns\n",
    "\n",
    "feature_lst = ['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5','PROC_10', 'wpr',\\\n",
    "                'sto_os', 'goog_trend_score', 'count', 'compound', 'retweets_count', 'likes_count', 'replies_count',\\\n",
    "                'compound_weighted_replies', 'compound_weighted_likes','compound_weighted_retweets',\\\n",
    "                'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', \\\n",
    "                'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500']\n",
    "\n",
    "outcome = features_df.columns[-1]\n",
    "\n",
    "print(feature_lst)\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1253, 24) (1253,)\n"
     ]
    }
   ],
   "source": [
    "X = features_df[feature_lst]\n",
    "y = features_df[outcome]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "Trying what Ana gave me for hyperparameter tuning (OPTUNA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING OPTUNA TO CHOOSE BEST HYPERPARAMETERS\n",
    "# this function came from Ana\n",
    "\n",
    "#https://towardsdatascience.com/state-of-the-art-machine-learning-hyperparameter-optimization-with-optuna-a315d8564de1\n",
    "def objective(trial:Trial, train = None, labels = None, val = None, val_labels = None, val_rets = None):\n",
    "    ada_m_depth = trial.suggest_int(\"max_depth\", 1, 5, step = 1)\n",
    "    ada_n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000, step = 50)\n",
    "    ada_learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1.0, step = .009)\n",
    "\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = ada_m_depth, random_state = 1234)\n",
    "    ada_clf = AdaBoostClassifier(base_estimator, \n",
    "                                n_estimators = ada_n_estimators,\n",
    "                                learning_rate = ada_learning_rate,\n",
    "                                algorithm = \"SAMME.R\")\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    #preds = ada_clf.predict(X_valid)\n",
    "    accuracy = ada_clf.score(X_valid, y_valid)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still From Ana\n",
    "#y_valid\n",
    "# y_valid = np.array(y_valid)\n",
    "# y_valid = y_valid.reshape(1, -1)\n",
    "#np.shape(y_valid)\n",
    "study = optuna.create_study(direction = \"maximize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7070063694267515\n",
      "Best Params: \n",
      "  max_depth: 1\n",
      "  n_estimators: 50\n",
      "  learning_rate: 0.009999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Line 3 and 6 is  from ANa\n",
    "\n",
    "#%%time \n",
    "\n",
    "# Line 6 is copy/pasted from Ana, have not updated to our data/var names at this point\n",
    "# study.optimize(partial(objective,train=train_1,labels=y_1,val=valid,val_labels=y_valid,val_rets=valid_stock_returns), n_trials=20,n_jobs=-1)\n",
    "\n",
    "# the below code doesn't work at this point but is me trying out oputna.\n",
    "study.optimize(objective, n_trials = 20, n_jobs = -1)\n",
    "\n",
    "\n",
    "trial = study.best_trial\n",
    "print(\"Best Score: \", trial.value)\n",
    "print(\"Best Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"  {}: {}\".format(key, value))\n",
    "\n",
    "    # create function to pass in objective?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of what Ana suggested\n",
    "\n",
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a regular decision tree model with different tree depth, \n",
    "use as comparison to show that adaboost is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1 , Score: 0.6327555555555555\n",
      "Depth: 2 , Score: 0.6455619047619047\n",
      "Depth: 3 , Score: 0.6512507936507935\n",
      "Depth: 4 , Score: 0.646431746031746\n",
      "Depth: 5 , Score: 0.6440253968253967\n",
      "Depth: 6 , Score: 0.6313523809523809\n",
      "Depth: 7 , Score: 0.6184888888888889\n",
      "Depth: 8 , Score: 0.6025269841269841\n",
      "Depth: 9 , Score: 0.5969523809523809\n",
      "Depth: 10 , Score: 0.6049015873015873\n",
      "Max depth should be: 3\n"
     ]
    }
   ],
   "source": [
    "# Figure out what the tree depth should be (maximum score)\n",
    "results_dict = {}\n",
    "cx_validation = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "for depth in range(1, 11):\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = depth, random_state = 1234)\n",
    "    if base_estimator.fit(X_train,y_train).tree_.max_depth < depth:\n",
    "        break\n",
    "    accuracy_score = np.mean(cross_val_score(base_estimator, X, y, cv = cx_validation, scoring = 'accuracy', n_jobs = 1))\n",
    "    print(\"Depth:\", depth, \", Score:\", accuracy_score)\n",
    "\n",
    "    results_dict[depth] = accuracy_score\n",
    "\n",
    "max_val = -1\n",
    "max_depth_val = None\n",
    "for key, val in results_dict.items():\n",
    "    if val > max_val:\n",
    "        max_val = val\n",
    "        max_depth_val = key\n",
    "\n",
    "print(\"Max depth should be:\", max_depth_val)\n",
    "\n",
    "    # https://educationalresearchtechniques.com/2019/01/02/adaboost-classification-in-python/\n",
    "    # https://towardsdatascience.com/boosting-and-adaboost-clearly-explained-856e21152d3e\n",
    "    # https://python-bloggers.com/2019/01/adaboost-classification-in-python/ # this one for \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight run of the model with default chosen n_estimators and learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "base_estimator = DecisionTreeClassifier(max_depth = 1, random_state = 1234)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7070063694267515\n",
      "MSE: 0.2929936305732484\n",
      "CONFUSION: [[ 91  45]\n",
      " [ 47 131]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and randomly chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)\n",
    "\n",
    "## Consider changing to this wiht the cross val score even for default/trying things out.\n",
    "# Probably leave at decision stump instead of max depth thing\n",
    "# https://medium.com/@chaudhurysrijani/tuning-of-adaboost-with-computational-complexity-8727d01a9d20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily_Change: 0.04\n",
      "Daily_Change_Ind: 0.0\n",
      "MACD: 0.04\n",
      "PROC_3: 0.1\n",
      "PROC_5: 0.06\n",
      "PROC_10: 0.08\n",
      "wpr: 0.06\n",
      "sto_os: 0.1\n",
      "goog_trend_score: 0.04\n",
      "count: 0.02\n",
      "compound: 0.02\n",
      "retweets_count: 0.06\n",
      "likes_count: 0.0\n",
      "replies_count: 0.04\n",
      "compound_weighted_replies: 0.0\n",
      "compound_weighted_likes: 0.08\n",
      "compound_weighted_retweets: 0.04\n",
      "Daily_Change_Perc: 0.12\n",
      "Daily_Change_Gold: 0.02\n",
      "Daily_Change_Perc_Gold: 0.04\n",
      "Increased_Gold: 0.0\n",
      "Daily_Change_SP500: 0.02\n",
      "Daily_Change_Perc_SP500: 0.02\n",
      "Increased_SP500: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_import = adaboost.feature_importances_\n",
    "for i in range(len(feature_lst)):\n",
    "    print(f\"{feature_lst[i]}: {feature_import[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper parametertuning (number estimators and learning rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuning n_estimators and learning_Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    "\n",
    "# alternative way to check n_estiamtors and learning_Rate\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid, n_jobs = -1, cv = cv, scoring = 'accuracy')\n",
    "\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun adaboost with chosen hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_n: 50\n",
      "chosen_learing_rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth = 1, random_state = 1234)\n",
    "\n",
    "chosen_learning_rate = list(grid_result.best_params_.values())[0]\n",
    "chosen_n = list(grid_result.best_params_.values())[1]\n",
    "\n",
    "print(\"chosen_n:\", chosen_n)\n",
    "print(\"chosen_learing_rate:\", chosen_learning_rate)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = chosen_n,\n",
    "                              learning_rate = chosen_learning_rate, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = adaboost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7165605095541401\n",
      "MSE: 0.28343949044585987\n",
      "CONFUSION: [[ 90  46]\n",
      " [ 43 135]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily_Change: 0.08\n",
      "Daily_Change_Ind: 0.0\n",
      "MACD: 0.0\n",
      "PROC_3: 0.24\n",
      "PROC_5: 0.26\n",
      "PROC_10: 0.0\n",
      "wpr: 0.14\n",
      "sto_os: 0.08\n",
      "goog_trend_score: 0.0\n",
      "count: 0.0\n",
      "compound: 0.0\n",
      "retweets_count: 0.0\n",
      "likes_count: 0.0\n",
      "replies_count: 0.0\n",
      "compound_weighted_replies: 0.0\n",
      "compound_weighted_likes: 0.0\n",
      "compound_weighted_retweets: 0.0\n",
      "Daily_Change_Perc: 0.18\n",
      "Daily_Change_Gold: 0.0\n",
      "Daily_Change_Perc_Gold: 0.02\n",
      "Increased_Gold: 0.0\n",
      "Daily_Change_SP500: 0.0\n",
      "Daily_Change_Perc_SP500: 0.0\n",
      "Increased_SP500: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_import = adaboost.feature_importances_\n",
    "for i in range(len(feature_lst)):\n",
    "    print(f\"{feature_lst[i]}: {feature_import[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try adjusting depth? This needs to be done simultaneously if at all...might be where optuna is helpful\n",
    "score = []\n",
    "for depth in [1,2,3] : \n",
    "    base_estimator = DecisionTreeClassifier(max_depth = depth, random_state = 1234)\n",
    "    adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = chosen_n,\n",
    "                              learning_rate = chosen_learning_rate, random_state = 1234)\n",
    "    scores_ada = cross_val_score(adaboost, X_train, y_train)\n",
    "    score.append(scores_ada.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [0.6581400729489901, 0.6720017420654364, 0.6113560890630954]\n"
     ]
    }
   ],
   "source": [
    "print(\"score\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' other links\n",
    "https://inria.github.io/scikit-learn-mooc/python_scripts/ensemble_adaboost.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    " https://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    " https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    " \n",
    " https://towardsdatascience.com/how-do-you-implement-adaboost-with-python-a76427b0fa7a\n",
    " https://towardsdatascience.com/machine-learning-part-17-boosting-algorithms-adaboost-in-python-d00faac6c464\n",
    " \n",
    " https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    " https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\n",
    " https://medium.datadriveninvestor.com/understanding-adaboost-and-scikit-learns-algorithm-c8d8af5ace10\n",
    " https://blog.paperspace.com/adaboost-optimizer/\n",
    " https://www.datacamp.com/tutorial/adaboost-classifier-python\n",
    " https://educationalresearchtechniques.com/2019/01/02/adaboost-classification-in-python/\n",
    "\n",
    " consider trying standardization https://github.com/mehuls45/Heart-Disease-prediction-using-ML/blob/master/AdaBoost.ipynb\n",
    "\n",
    " # no need to normalize/standardize in ensemble methods \n",
    " https://towardsdatascience.com/the-ultimate-guide-to-adaboost-random-forests-and-xgboost-7f9327061c4f\n",
    "\n",
    " https://github.com/julianikulski/bike-sharing/blob/master/bike_sharing_demand.ipynb\n",
    "\n",
    "https://www.google.com/search?client=firefox-b-1-d&q=hyperparameter+tuning+adaboost\n",
    " https://stackoverflow.com/questions/32210569/using-gridsearchcv-with-adaboost-and-decisiontreeclassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for Dogecoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"bitcoin_train.csv\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "MISC OTHER CODE NOT USING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------\n",
    "We will evaluate the model using repeated stratified k-fold cross-validation, with three repeats and 10 folds. We will report the mean and standard deviation of the accuracy of the model across all repeats and folds.\n",
    "\n",
    "https://machinelearningmastery.com/adaboost-ensemble-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.635 (0.053)\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1234)\n",
    "n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This achieved 63.5% accuracy with default hyperparameters. Now make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7070063694267515\n",
      "MSE: 0.2929936305732484\n",
      "CONFUSION: [[ 91  45]\n",
      " [ 47 131]]\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X_train, y_train)\n",
    "# make a single prediction\n",
    "y_hat = model.predict(X_valid)\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "                   base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                         random_state=1234),\n",
       "                   n_estimators=3, random_state=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth=3, random_state=1234)\n",
    "adaboost = AdaBoostClassifier(base_estimator=base_estimator,\n",
    "                              n_estimators=3, algorithm=\"SAMME\",\n",
    "                              random_state=0)\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DecisionBoundaryDisplay' from 'sklearn.inspection' (/home/ksarussi/.local/lib/python3.8/site-packages/sklearn/inspection/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb Cell 37'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000039vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000039vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000039vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minspection\u001b[39;00m \u001b[39mimport\u001b[39;00m DecisionBoundaryDisplay\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DecisionBoundaryDisplay' from 'sklearn.inspection' (/home/ksarussi/.local/lib/python3.8/site-packages/sklearn/inspection/__init__.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionBoundaryDisplay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb Cell 38'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000038vscode-remote?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000038vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# we convert `data` into a NumPy array to avoid a warning raised in scikit-learn\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000038vscode-remote?line=3'>4</a>\u001b[0m DecisionBoundaryDisplay\u001b[39m.\u001b[39mfrom_estimator(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000038vscode-remote?line=4'>5</a>\u001b[0m     tree, X_train\u001b[39m.\u001b[39mto_numpy(), response_method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m, cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRdBu\u001b[39m\u001b[39m\"\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000038vscode-remote?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000038vscode-remote?line=6'>7</a>\u001b[0m sns\u001b[39m.\u001b[39mscatterplot(x\u001b[39m=\u001b[39mculmen_columns[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mculmen_columns[\u001b[39m1\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000038vscode-remote?line=7'>8</a>\u001b[0m                 hue\u001b[39m=\u001b[39mtarget_column, data\u001b[39m=\u001b[39mpenguins,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000038vscode-remote?line=8'>9</a>\u001b[0m                 palette\u001b[39m=\u001b[39mpalette)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000038vscode-remote?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend(bbox_to_anchor\u001b[39m=\u001b[39m(\u001b[39m1.04\u001b[39m, \u001b[39m0.5\u001b[39m), loc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcenter left\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionBoundaryDisplay' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for boosting_round, tree in enumerate(adaboost.estimators_):\n",
    "    plt.figure()\n",
    "    # we convert `data` into a NumPy array to avoid a warning raised in scikit-learn\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        tree, X_train.to_numpy(), response_method=\"predict\", cmap=\"RdBu\", alpha=0.5\n",
    "    )\n",
    "    sns.scatterplot(x=culmen_columns[0], y=culmen_columns[1],\n",
    "                    hue=target_column, data=penguins,\n",
    "                    palette=palette)\n",
    "    plt.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\")\n",
    "    _ = plt.title(f\"Decision tree trained at round {boosting_round}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parametertuning (number estimators and learning rate)\n",
    "# ada = AdaBoostClassifier()\n",
    "# search_grid = {'n_estimators':[500,1000,2000], 'learning_rate':[.001,0.01,.1]}\n",
    "# search = GridSearchCV(estimator = ada, param_grid = search_grid, scoring = 'accuracy', n_jobs = 1, cv = cx_validation)\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/\n",
    "\n",
    "# search.fit(X,y)\n",
    "# search.best_params_\n",
    "# print(search.best_params_)\n",
    "# search.best_score_\n",
    "# print(search.best_score_)\n",
    "#Out[34]: 0.7425149700598802\n",
    "\n",
    "\n",
    "\n",
    "# https://python-bloggers.com/2019/01/adaboost-classification-in-python/\n",
    "\n",
    "# score = np.mean(cross_val_score(ada, X, y, scoring='accuracy', cv = cx_validation, n_jobs = 1))\n",
    "# score\n",
    "\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/\n",
    "\n",
    "# AdaBoostClassifier.get_params().keys()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
