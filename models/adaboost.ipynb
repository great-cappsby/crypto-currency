{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksarussi/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Change</th>\n",
       "      <th>Daily_Change_Ind</th>\n",
       "      <th>MACD</th>\n",
       "      <th>...</th>\n",
       "      <th>Open_Gold</th>\n",
       "      <th>Daily_Change_Gold</th>\n",
       "      <th>Daily_Change_Perc_Gold</th>\n",
       "      <th>Increased_Gold</th>\n",
       "      <th>Close/Last_SP500</th>\n",
       "      <th>Open_SP500</th>\n",
       "      <th>Daily_Change_SP500</th>\n",
       "      <th>Daily_Change_Perc_SP500</th>\n",
       "      <th>Increased_SP500</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>15864.099609</td>\n",
       "      <td>15888.400391</td>\n",
       "      <td>13937.299805</td>\n",
       "      <td>14606.500000</td>\n",
       "      <td>12336499712</td>\n",
       "      <td>-1232.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636.405515</td>\n",
       "      <td>...</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>1</td>\n",
       "      <td>2687.54</td>\n",
       "      <td>2686.10</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>908</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>6342.750000</td>\n",
       "      <td>6707.140137</td>\n",
       "      <td>6334.459961</td>\n",
       "      <td>6675.350098</td>\n",
       "      <td>5138710016</td>\n",
       "      <td>325.450196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-383.201570</td>\n",
       "      <td>...</td>\n",
       "      <td>1303.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>1</td>\n",
       "      <td>2782.49</td>\n",
       "      <td>2783.21</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224</td>\n",
       "      <td>2015-09-25</td>\n",
       "      <td>234.362000</td>\n",
       "      <td>237.427002</td>\n",
       "      <td>233.684006</td>\n",
       "      <td>235.143997</td>\n",
       "      <td>22363600</td>\n",
       "      <td>0.614990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.731076</td>\n",
       "      <td>...</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-0.004692</td>\n",
       "      <td>0</td>\n",
       "      <td>1931.34</td>\n",
       "      <td>1935.93</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1042</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>3819.666748</td>\n",
       "      <td>3893.359619</td>\n",
       "      <td>3769.863770</td>\n",
       "      <td>3857.297607</td>\n",
       "      <td>5326547918</td>\n",
       "      <td>41.806884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-83.043066</td>\n",
       "      <td>...</td>\n",
       "      <td>1273.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0</td>\n",
       "      <td>2467.70</td>\n",
       "      <td>2363.12</td>\n",
       "      <td>104.58</td>\n",
       "      <td>0.044255</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>563</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>972.018982</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>970.403015</td>\n",
       "      <td>164582000</td>\n",
       "      <td>50.020996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.846431</td>\n",
       "      <td>...</td>\n",
       "      <td>1197.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>1</td>\n",
       "      <td>2278.87</td>\n",
       "      <td>2274.02</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date          Open          High           Low  \\\n",
       "0         793  2017-12-28  15864.099609  15888.400391  13937.299805   \n",
       "1         908  2018-06-14   6342.750000   6707.140137   6334.459961   \n",
       "2         224  2015-09-25    234.362000    237.427002    233.684006   \n",
       "3        1042  2018-12-26   3819.666748   3893.359619   3769.863770   \n",
       "4         563  2017-01-31    920.958984    972.018982    920.958984   \n",
       "\n",
       "          Close       Volume  Daily_Change  Daily_Change_Ind        MACD  ...  \\\n",
       "0  14606.500000  12336499712  -1232.000000               0.0  636.405515  ...   \n",
       "1   6675.350098   5138710016    325.450196               1.0 -383.201570  ...   \n",
       "2    235.143997     22363600      0.614990               1.0   -1.731076  ...   \n",
       "3   3857.297607   5326547918     41.806884               1.0  -83.043066  ...   \n",
       "4    970.403015    164582000     50.020996               1.0   12.846431  ...   \n",
       "\n",
       "   Open_Gold  Daily_Change_Gold  Daily_Change_Perc_Gold  Increased_Gold  \\\n",
       "0     1292.0                5.2                0.004025               1   \n",
       "1     1303.1                5.2                0.003990               1   \n",
       "2     1151.0               -5.4               -0.004692               0   \n",
       "3     1273.5               -0.5               -0.000393               0   \n",
       "4     1197.7               13.7                0.011439               1   \n",
       "\n",
       "   Close/Last_SP500  Open_SP500  Daily_Change_SP500  Daily_Change_Perc_SP500  \\\n",
       "0           2687.54     2686.10                1.44                 0.000536   \n",
       "1           2782.49     2783.21               -0.72                -0.000259   \n",
       "2           1931.34     1935.93               -4.59                -0.002371   \n",
       "3           2467.70     2363.12              104.58                 0.044255   \n",
       "4           2278.87     2274.02                4.85                 0.002133   \n",
       "\n",
       "   Increased_SP500  label  \n",
       "0                1    0.0  \n",
       "1                0    0.0  \n",
       "2                0    1.0  \n",
       "3                1    1.0  \n",
       "4                1    1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv(\"bitcoin_train.csv\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5', 'PROC_10', 'wpr', 'sto_os', 'goog_trend_score', 'count', 'compound', 'retweets_count', 'likes_count', 'replies_count', 'compound_weighted_replies', 'compound_weighted_likes', 'compound_weighted_retweets', 'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', 'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500']\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "features_df.columns\n",
    "\n",
    "feature_lst = ['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5','PROC_10', 'wpr',\\\n",
    "                'sto_os', 'goog_trend_score', 'count', 'compound', 'retweets_count', 'likes_count', 'replies_count',\\\n",
    "                'compound_weighted_replies', 'compound_weighted_likes','compound_weighted_retweets',\\\n",
    "                'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', \\\n",
    "                'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500']\n",
    "\n",
    "outcome = features_df.columns[-1]\n",
    "\n",
    "print(feature_lst)\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1253, 24) (1253,)\n"
     ]
    }
   ],
   "source": [
    "X = features_df[feature_lst]\n",
    "y = features_df[outcome]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying what Ana gave me for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING OPTUNA TO CHOOSE BEST HYPERPARAMETERS\n",
    "# this function came from Ana\n",
    "\n",
    "#https://towardsdatascience.com/state-of-the-art-machine-learning-hyperparameter-optimization-with-optuna-a315d8564de1\n",
    "def objective(trial:Trial, train = None, labels = None, val = None, val_labels = None, val_rets = None):\n",
    "    ada_m_depth = trial.suggest_int(\"max_depth\", 1, 5, step = 1)\n",
    "    ada_n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000, step = 50)\n",
    "    ada_learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1.0, step = .009)\n",
    "\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = ada_m_depth, random_state = 1234)\n",
    "    ada_clf = AdaBoostClassifier(base_estimator, \n",
    "                                n_estimators = ada_n_estimators,\n",
    "                                learning_rate = ada_learning_rate,\n",
    "                                algorithm = \"SAMME.R\")\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    preds = ada_clf.predict(X_valid)\n",
    "    accuracy = ada_clf.score(y_valid, y_hat)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#y_valid\n",
    "# y_valid = np.array(y_valid)\n",
    "# y_valid = y_valid.reshape(1, -1)\n",
    "#np.shape(y_valid)\n",
    "study = optuna.create_study(direction = \"maximize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time \n",
    "\n",
    "# Line 4 is copy/pasted from Ana, have not updated to our data/var names at this point\n",
    "# study.optimize(partial(objective,train=train_1,labels=y_1,val=valid,val_labels=y_valid,val_rets=valid_stock_returns), n_trials=20,n_jobs=-1)\n",
    "\n",
    "\n",
    "# trying this line of code cause idk what the partial thing is in line 4. This doesn't work either.\n",
    "study.optimize(objective, n_trials = 20, n_jobs = -1)\n",
    "# trial = study.best_trial\n",
    "# print(\"Best Score: \", trial.value)\n",
    "# print(\"Best Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(\"  {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing best tree depth based on regular decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1 , Score: 0.6327555555555555\n",
      "Depth: 2 , Score: 0.6455619047619047\n",
      "Depth: 3 , Score: 0.6512507936507935\n",
      "Depth: 4 , Score: 0.646431746031746\n",
      "Depth: 5 , Score: 0.6440253968253967\n",
      "Depth: 6 , Score: 0.6313523809523809\n",
      "Depth: 7 , Score: 0.6184888888888889\n",
      "Depth: 8 , Score: 0.6025269841269841\n",
      "Depth: 9 , Score: 0.5969523809523809\n",
      "Depth: 10 , Score: 0.6049015873015873\n",
      "Max depth should be: 3\n"
     ]
    }
   ],
   "source": [
    "# Figure out what the tree depth should be (maximum score)\n",
    "results_dict = {}\n",
    "cx_validation = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "for depth in range(1, 11):\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = depth, random_state = 1234)\n",
    "    if base_estimator.fit(X_train,y_train).tree_.max_depth < depth:\n",
    "        break\n",
    "    accuracy_score = np.mean(cross_val_score(base_estimator, X, y, cv = cx_validation, scoring = 'accuracy', n_jobs = 1))\n",
    "    print(\"Depth:\", depth, \", Score:\", accuracy_score)\n",
    "\n",
    "    results_dict[depth] = accuracy_score\n",
    "\n",
    "max_val = -1\n",
    "max_depth_val = None\n",
    "for key, val in results_dict.items():\n",
    "    if val > max_val:\n",
    "        max_val = val\n",
    "        max_depth_val = key\n",
    "\n",
    "print(\"Max depth should be:\", max_depth_val)\n",
    "\n",
    "    # https://educationalresearchtechniques.com/2019/01/02/adaboost-classification-in-python/\n",
    "    # https://towardsdatascience.com/boosting-and-adaboost-clearly-explained-856e21152d3e\n",
    "    # https://python-bloggers.com/2019/01/adaboost-classification-in-python/ # this one for \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight run of the model with randomly chosen n_estimators and learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "base_estimator = DecisionTreeClassifier(max_depth = 1, random_state = 1234)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = 20,\n",
    "                              learning_rate = 1, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6910828025477707\n",
      "MSE: 0.3089171974522293\n",
      "CONFUSION: [[ 91  45]\n",
      " [ 52 126]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and randomly chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)\n",
    "\n",
    "\n",
    "\n",
    "## Consider changing to this wiht the cross val score even for default/trying things out.\n",
    "# Probably leave at decision stump instead of max depth thing\n",
    "# https://medium.com/@chaudhurysrijani/tuning-of-adaboost-with-computational-complexity-8727d01a9d20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to look at whihc feature is most important. This will be one feature if decision tree depth = 1?\n",
    "# new = model.predict(adaboost.feature_importances_)\n",
    "# for i in range(len(feature_lst)):\n",
    "#     print(f\"{feature_lst[i]}: {feature_import[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper parametertuning (number estimators and learning rate)\n",
    "Ignore 1st three commented out  cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parametertuning (number estimators and learning rate)\n",
    "# ada = AdaBoostClassifier()\n",
    "# search_grid = {'n_estimators':[500,1000,2000], 'learning_rate':[.001,0.01,.1]}\n",
    "# search = GridSearchCV(estimator = ada, param_grid = search_grid, scoring = 'accuracy', n_jobs = 1, cv = cx_validation)\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search.fit(X,y)\n",
    "# search.best_params_\n",
    "# print(search.best_params_)\n",
    "# search.best_score_\n",
    "# print(search.best_score_)\n",
    "#Out[34]: 0.7425149700598802\n",
    "\n",
    "\n",
    "\n",
    "# https://python-bloggers.com/2019/01/adaboost-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6472126984126984"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score = np.mean(cross_val_score(ada, X, y, scoring='accuracy', cv = cx_validation, n_jobs = 1))\n",
    "# score\n",
    "\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_params() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000025vscode-remote?line=0'>1</a>\u001b[0m AdaBoostClassifier\u001b[39m.\u001b[39;49mget_params()\u001b[39m.\u001b[39mkeys()\n",
      "\u001b[0;31mTypeError\u001b[0m: get_params() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuning n_estimators and learning_Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter depth for estimator AdaBoostClassifier(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ksarussi/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/home/ksarussi/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/ksarussi/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"/home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 668, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/home/ksarussi/.local/lib/python3.8/site-packages/sklearn/base.py\", line 245, in set_params\n    raise ValueError(\nValueError: Invalid parameter depth for estimator AdaBoostClassifier(). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000017vscode-remote?line=12'>13</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator \u001b[39m=\u001b[39m model, param_grid \u001b[39m=\u001b[39m grid, n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv \u001b[39m=\u001b[39m cv, scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000017vscode-remote?line=13'>14</a>\u001b[0m \u001b[39m# execute the grid search\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000017vscode-remote?line=14'>15</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000017vscode-remote?line=15'>16</a>\u001b[0m \u001b[39m# summarize the best score and configuration\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000017vscode-remote?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (grid_result\u001b[39m.\u001b[39mbest_score_, grid_result\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=1389'>1390</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=1390'>1391</a>\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=1391'>1392</a>\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1052'>1053</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1054'>1055</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1055'>1056</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1056'>1057</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=1057'>1058</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=932'>933</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=933'>934</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=934'>935</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=935'>936</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/parallel.py?line=936'>937</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=538'>539</a>\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=539'>540</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=540'>541</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=541'>542</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=542'>543</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=543'>544</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=441'>442</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=442'>443</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=443'>444</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=444'>445</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=445'>446</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=386'>387</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=387'>388</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=388'>389</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=389'>390</a>\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=390'>391</a>\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=391'>392</a>\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter depth for estimator AdaBoostClassifier(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    "\n",
    "# alternative way to check n_estiamtors and learning_Rate\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "#grid[\"depth\"] = [1, 2, 3, 4, 5]\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid, n_jobs = -1, cv = cv, scoring = 'accuracy')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun adaboost with chosen hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_n: 500\n",
      "chosen_learing_rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth = 1, random_state = 1234)\n",
    "\n",
    "chosen_learning_rate = list(grid_result.best_params_.values())[0]\n",
    "chosen_n = list(grid_result.best_params_.values())[1]\n",
    "\n",
    "print(\"chosen_n:\", chosen_n)\n",
    "print(\"chosen_learing_rate:\", chosen_learning_rate)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = chosen_n,\n",
    "                              learning_rate = chosen_learning_rate, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7070063694267515\n",
      "MSE: 0.2929936305732484\n",
      "CONFUSION: [[ 90  46]\n",
      " [ 46 132]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' other links\n",
    "https://inria.github.io/scikit-learn-mooc/python_scripts/ensemble_adaboost.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    " https://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    " https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    " \n",
    " https://towardsdatascience.com/how-do-you-implement-adaboost-with-python-a76427b0fa7a\n",
    " https://towardsdatascience.com/machine-learning-part-17-boosting-algorithms-adaboost-in-python-d00faac6c464\n",
    " \n",
    " https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    " https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\n",
    " https://medium.datadriveninvestor.com/understanding-adaboost-and-scikit-learns-algorithm-c8d8af5ace10\n",
    " https://blog.paperspace.com/adaboost-optimizer/\n",
    " https://www.datacamp.com/tutorial/adaboost-classifier-python\n",
    " https://educationalresearchtechniques.com/2019/01/02/adaboost-classification-in-python/\n",
    "\n",
    " consider trying standardization https://github.com/mehuls45/Heart-Disease-prediction-using-ML/blob/master/AdaBoost.ipynb\n",
    "\n",
    " # no need to normalize/standardize in ensemble methods \n",
    " https://towardsdatascience.com/the-ultimate-guide-to-adaboost-random-forests-and-xgboost-7f9327061c4f\n",
    "\n",
    " https://github.com/julianikulski/bike-sharing/blob/master/bike_sharing_demand.ipynb\n",
    "\n",
    "https://www.google.com/search?client=firefox-b-1-d&q=hyperparameter+tuning+adaboost\n",
    " https://stackoverflow.com/questions/32210569/using-gridsearchcv-with-adaboost-and-decisiontreeclassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for Dogecoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"bitcoin_train.csv\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000022vscode-remote?line=29'>30</a>\u001b[0m \tnames\u001b[39m.\u001b[39mappend(name)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000022vscode-remote?line=30'>31</a>\u001b[0m \t\u001b[39m# summarize the performance along the way\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000022vscode-remote?line=31'>32</a>\u001b[0m \t\u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (name, mean(scores), std(scores)))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000022vscode-remote?line=32'>33</a>\u001b[0m \u001b[39m# plot model performance for comparison\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000022vscode-remote?line=33'>34</a>\u001b[0m pyplot\u001b[39m.\u001b[39mboxplot(results, labels\u001b[39m=\u001b[39mnames, showmeans\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# explore depths from 1 to 10\n",
    "\tfor i in range(1,11):\n",
    "\t\t# define base model\n",
    "\t\tbase = DecisionTreeClassifier(max_depth=i)\n",
    "\t\t# define ensemble model\n",
    "\t\tmodels[str(i)] = AdaBoostClassifier(base_estimator=base)\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\t# store the results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize the performance along the way\n",
    "\tprint('%s %f (%f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()\n",
    "\n",
    "    #print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
