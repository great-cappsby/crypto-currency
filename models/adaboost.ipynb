{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Change</th>\n",
       "      <th>Daily_Change_Ind</th>\n",
       "      <th>MACD</th>\n",
       "      <th>...</th>\n",
       "      <th>Open_Gold</th>\n",
       "      <th>Daily_Change_Gold</th>\n",
       "      <th>Daily_Change_Perc_Gold</th>\n",
       "      <th>Increased_Gold</th>\n",
       "      <th>Close/Last_SP500</th>\n",
       "      <th>Open_SP500</th>\n",
       "      <th>Daily_Change_SP500</th>\n",
       "      <th>Daily_Change_Perc_SP500</th>\n",
       "      <th>Increased_SP500</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>15864.099609</td>\n",
       "      <td>15888.400391</td>\n",
       "      <td>13937.299805</td>\n",
       "      <td>14606.500000</td>\n",
       "      <td>12336499712</td>\n",
       "      <td>-1232.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636.405515</td>\n",
       "      <td>...</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>1</td>\n",
       "      <td>2687.54</td>\n",
       "      <td>2686.10</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>908</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>6342.750000</td>\n",
       "      <td>6707.140137</td>\n",
       "      <td>6334.459961</td>\n",
       "      <td>6675.350098</td>\n",
       "      <td>5138710016</td>\n",
       "      <td>325.450196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-383.201570</td>\n",
       "      <td>...</td>\n",
       "      <td>1303.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>1</td>\n",
       "      <td>2782.49</td>\n",
       "      <td>2783.21</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224</td>\n",
       "      <td>2015-09-25</td>\n",
       "      <td>234.362000</td>\n",
       "      <td>237.427002</td>\n",
       "      <td>233.684006</td>\n",
       "      <td>235.143997</td>\n",
       "      <td>22363600</td>\n",
       "      <td>0.614990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.731076</td>\n",
       "      <td>...</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-0.004692</td>\n",
       "      <td>0</td>\n",
       "      <td>1931.34</td>\n",
       "      <td>1935.93</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1042</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>3819.666748</td>\n",
       "      <td>3893.359619</td>\n",
       "      <td>3769.863770</td>\n",
       "      <td>3857.297607</td>\n",
       "      <td>5326547918</td>\n",
       "      <td>41.806884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-83.043066</td>\n",
       "      <td>...</td>\n",
       "      <td>1273.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0</td>\n",
       "      <td>2467.70</td>\n",
       "      <td>2363.12</td>\n",
       "      <td>104.58</td>\n",
       "      <td>0.044255</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>563</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>972.018982</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>970.403015</td>\n",
       "      <td>164582000</td>\n",
       "      <td>50.020996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.846431</td>\n",
       "      <td>...</td>\n",
       "      <td>1197.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>1</td>\n",
       "      <td>2278.87</td>\n",
       "      <td>2274.02</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date          Open          High           Low  \\\n",
       "0         793  2017-12-28  15864.099609  15888.400391  13937.299805   \n",
       "1         908  2018-06-14   6342.750000   6707.140137   6334.459961   \n",
       "2         224  2015-09-25    234.362000    237.427002    233.684006   \n",
       "3        1042  2018-12-26   3819.666748   3893.359619   3769.863770   \n",
       "4         563  2017-01-31    920.958984    972.018982    920.958984   \n",
       "\n",
       "          Close       Volume  Daily_Change  Daily_Change_Ind        MACD  ...  \\\n",
       "0  14606.500000  12336499712  -1232.000000               0.0  636.405515  ...   \n",
       "1   6675.350098   5138710016    325.450196               1.0 -383.201570  ...   \n",
       "2    235.143997     22363600      0.614990               1.0   -1.731076  ...   \n",
       "3   3857.297607   5326547918     41.806884               1.0  -83.043066  ...   \n",
       "4    970.403015    164582000     50.020996               1.0   12.846431  ...   \n",
       "\n",
       "   Open_Gold  Daily_Change_Gold  Daily_Change_Perc_Gold  Increased_Gold  \\\n",
       "0     1292.0                5.2                0.004025               1   \n",
       "1     1303.1                5.2                0.003990               1   \n",
       "2     1151.0               -5.4               -0.004692               0   \n",
       "3     1273.5               -0.5               -0.000393               0   \n",
       "4     1197.7               13.7                0.011439               1   \n",
       "\n",
       "   Close/Last_SP500  Open_SP500  Daily_Change_SP500  Daily_Change_Perc_SP500  \\\n",
       "0           2687.54     2686.10                1.44                 0.000536   \n",
       "1           2782.49     2783.21               -0.72                -0.000259   \n",
       "2           1931.34     1935.93               -4.59                -0.002371   \n",
       "3           2467.70     2363.12              104.58                 0.044255   \n",
       "4           2278.87     2274.02                4.85                 0.002133   \n",
       "\n",
       "   Increased_SP500  label  \n",
       "0                1    0.0  \n",
       "1                0    0.0  \n",
       "2                0    1.0  \n",
       "3                1    1.0  \n",
       "4                1    1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv(\"bitcoin_train.csv\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5', 'PROC_10', 'wpr', 'sto_os', 'goog_trend_score', 'count', 'compound', 'retweets_count', 'likes_count', 'replies_count', 'compound_weighted_replies', 'compound_weighted_likes', 'compound_weighted_retweets', 'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', 'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500']\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "features_df.columns\n",
    "\n",
    "feature_lst = ['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5','PROC_10', 'wpr',\\\n",
    "                'sto_os', 'goog_trend_score', 'count', 'compound', 'retweets_count', 'likes_count', 'replies_count',\\\n",
    "                'compound_weighted_replies', 'compound_weighted_likes','compound_weighted_retweets',\\\n",
    "                'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', \\\n",
    "                'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500']\n",
    "\n",
    "outcome = features_df.columns[-1]\n",
    "\n",
    "print(feature_lst)\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1253, 24) (1253,)\n"
     ]
    }
   ],
   "source": [
    "X = features_df[feature_lst]\n",
    "y = features_df[outcome]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1 , Score: 0.6327555555555555\n",
      "Depth: 2 , Score: 0.6455619047619047\n",
      "Depth: 3 , Score: 0.6512507936507935\n",
      "Depth: 4 , Score: 0.646431746031746\n",
      "Depth: 5 , Score: 0.6440253968253967\n",
      "Depth: 6 , Score: 0.6313523809523809\n",
      "Depth: 7 , Score: 0.6184888888888889\n",
      "Depth: 8 , Score: 0.6025269841269841\n",
      "Depth: 9 , Score: 0.5969523809523809\n",
      "Depth: 10 , Score: 0.6049015873015873\n",
      "Max depth should be: 3\n"
     ]
    }
   ],
   "source": [
    "# Figure out what the tree depth should be (maximum score)\n",
    "results_dict = {}\n",
    "cx_validation = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "for depth in range(1, 11):\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = depth, random_state = 1234)\n",
    "    if base_estimator.fit(X,y).tree_.max_depth < depth:\n",
    "        break\n",
    "    accuracy_score = np.mean(cross_val_score(base_estimator, X, y, cv = cx_validation, scoring = 'accuracy', n_jobs = 1))\n",
    "    print(\"Depth:\", depth, \", Score:\", accuracy_score)\n",
    "\n",
    "    results_dict[depth] = accuracy_score\n",
    "\n",
    "max_val = -1\n",
    "max_depth_val = None\n",
    "for key, val in results_dict.items():\n",
    "    if val > max_val:\n",
    "        max_val = val\n",
    "        max_depth_val = key\n",
    "\n",
    "print(\"Max depth should be:\", max_depth_val)\n",
    "\n",
    "    # https://educationalresearchtechniques.com/2019/01/02/adaboost-classification-in-python/\n",
    "    # https://towardsdatascience.com/boosting-and-adaboost-clearly-explained-856e21152d3e\n",
    "    # https://python-bloggers.com/2019/01/adaboost-classification-in-python/ # this one for \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "base_estimator = DecisionTreeClassifier(max_depth = max_depth_val, random_state = 1234)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = 20,\n",
    "                              learning_rate = 1, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.589171974522293\n",
      "MSE: 0.410828025477707\n",
      "CONFUSION: [[ 75  61]\n",
      " [ 68 110]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and randomly chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper parametertuning (number estimators and learning rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parametertuning (number estimators and learning rate)\n",
    "ada = AdaBoostClassifier()\n",
    "search_grid = {'n_estimators':[500,1000,2000], 'learning_rate':[.001,0.01,.1]}\n",
    "search = GridSearchCV(estimator = ada, param_grid = search_grid, scoring = 'accuracy', n_jobs = 1, cv = cx_validation)\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.6839047619047618\n"
     ]
    }
   ],
   "source": [
    "search.fit(X,y)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "search.best_score_\n",
    "print(search.best_score_)\n",
    "#Out[34]: 0.7425149700598802\n",
    "\n",
    "\n",
    "\n",
    "# https://python-bloggers.com/2019/01/adaboost-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6472126984126984"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = np.mean(cross_val_score(ada, X, y, scoring='accuracy', cv = cx_validation, n_jobs = 1))\n",
    "score\n",
    "\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.681812 using {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.640842 (0.034224) with: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "0.644830 (0.031782) with: {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "0.648298 (0.031138) with: {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "0.670358 (0.042053) with: {'learning_rate': 0.001, 'n_estimators': 500}\n",
      "0.677280 (0.037879) with: {'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "0.643767 (0.030720) with: {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "0.670093 (0.041589) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.677280 (0.037879) with: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.681812 (0.033829) with: {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.678356 (0.037315) with: {'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.679943 (0.039659) with: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.680222 (0.034767) with: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.679422 (0.037337) with: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.674610 (0.041927) with: {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.662902 (0.048804) with: {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "0.660783 (0.040680) with: {'learning_rate': 1.0, 'n_estimators': 10}\n",
      "0.657331 (0.037030) with: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.647490 (0.038654) with: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.623818 (0.043057) with: {'learning_rate': 1.0, 'n_estimators': 500}\n",
      "0.610800 (0.041446) with: {'learning_rate': 1.0, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    "\n",
    "# alternative way to check n_estiamtors and learning_Rate\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun adaboost with chosen hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_n 500\n",
      "chosen_learing_rate 0.01\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth = max_depth_val, random_state = 1234)\n",
    "\n",
    "chosen_learning_rate = list(grid_result.best_params_.values())[0]\n",
    "chosen_n = list(grid_result.best_params_.values())[1]\n",
    "\n",
    "print(\"chosen_n\", chosen_n)\n",
    "print(\"chosen_learing_rate\", chosen_learning_rate)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = chosen_n,\n",
    "                              learning_rate = chosen_learning_rate, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6401273885350318\n",
      "MSE: 0.35987261146496813\n",
      "CONFUSION: [[ 79  57]\n",
      " [ 56 122]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' other links\n",
    "https://inria.github.io/scikit-learn-mooc/python_scripts/ensemble_adaboost.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    " https://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    " https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    " \n",
    " https://towardsdatascience.com/how-do-you-implement-adaboost-with-python-a76427b0fa7a\n",
    " https://towardsdatascience.com/machine-learning-part-17-boosting-algorithms-adaboost-in-python-d00faac6c464\n",
    " \n",
    " https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    " https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\n",
    " https://medium.datadriveninvestor.com/understanding-adaboost-and-scikit-learns-algorithm-c8d8af5ace10\n",
    " https://blog.paperspace.com/adaboost-optimizer/\n",
    " https://www.datacamp.com/tutorial/adaboost-classifier-python\n",
    " https://educationalresearchtechniques.com/2019/01/02/adaboost-classification-in-python/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
